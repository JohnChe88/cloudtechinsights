{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02664559-a324-4085-be12-9c54d566b2a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Amazon Bedrock Agent -Code Interpreter Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad61abc-dc8f-46a5-9283-7fa861c7099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time, random \n",
    "import uuid, string\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b87e2f-482a-41a6-a5cb-23068e751989",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pick the foundation model as of today 08/01/2024 Sonnet and Haiku are supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfeaba31-dac4-4840-a123-9c3e2ed691d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_name = 'us-east-1'\n",
    "\n",
    "# The foundation model to use (for 'code interpreter' it must either Sonnet or Haiku).\n",
    "foundationModel = 'anthropic.claude-3-sonnet-20240229-v1:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d5a110-1d58-4822-8582-894f4d5df8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomSuffix = \"\".join(\n",
    "    random.choices(string.ascii_uppercase + string.digits, k=5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d397d15-998b-4396-91b1-0a8a56188286",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create the IAM policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4edf54ba-aeea-405f-95cf-3692b2995520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the IAM policy and role...\n",
      "IAM Role: arn:aws:iam::************:role/test-agent-FYS00\n"
     ]
    }
   ],
   "source": [
    "# Load IAM policies from JSON files\n",
    "with open('trust_policy.json') as f:\n",
    "    trust_policy = json.load(f)\n",
    "\n",
    "with open('bedrock_Agent_policy.json') as f:\n",
    "    policy = json.load(f)\n",
    "\n",
    "# Initialize IAM client\n",
    "iam = boto3.client('iam')\n",
    "\n",
    "# Generate a random suffix for unique naming\n",
    "random_suffix = ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))\n",
    "role_name = f\"test-agent-{random_suffix}\"\n",
    "\n",
    "print(\"Creating the IAM policy and role...\")\n",
    "\n",
    "# Create IAM role and attach policy\n",
    "role = iam.create_role(\n",
    "    RoleName=role_name,\n",
    "    AssumeRolePolicyDocument=json.dumps(trust_policy)\n",
    ")\n",
    "iam.put_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyName=f\"policy-test-agent1-{random_suffix}\",\n",
    "    PolicyDocument=json.dumps(policy)\n",
    ")\n",
    "\n",
    "roleArn = role['Role']['Arn']\n",
    "print(f\"IAM Role: {roleArn[:13]}{'*' * 12}{roleArn[25:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed677043-c42c-4e5d-8dc9-7f5eaa22c377",
   "metadata": {},
   "source": [
    "###  Set up Bedrock Agent and IAM clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb2b2bc-4071-452c-8ee9-72638cdc5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bedrock_agent = boto3.client(service_name = 'bedrock-agent', region_name = region_name)\n",
    "\n",
    "\n",
    "agentName = 'code-interpreter-test-agent1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c718bfcc-22df-4f3e-abf1-13f181a818a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Defining the Bedrock Agent PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68436cfb-9196-4fe0-a647-596306f370b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the agent's personality and behavior\n",
    "instruction = \"\"\"You are an AI agent with features for code execution, code generation, and data analysis. Your primary function is to assist users by solving problems and fulfilling requests through these capabilities. Here are your key attributes and instructions:\n",
    "\n",
    "Code Execution\n",
    "Python Environment: You have access to a Python environment where you can write and execute code in real-time.\n",
    "Accuracy: When asked to perform calculations or data manipulations, always use this code execution capability to ensure accuracy.\n",
    "Reporting: After executing code, report the exact output and explain the results.\n",
    "Data Analysis\n",
    "Complex Data Analysis: You excel at complex data analysis tasks. This includes statistical analysis and machine learning applications.\n",
    "Systematic Approach: Approach data analysis tasks systematically: understand the problem, prepare the data, perform the analysis, and interpret the results.\n",
    "Problem-Solving Approach\n",
    "Step-by-Step Breakdown: When presented with a problem or request, break it down into steps.\n",
    "Clear Communication: Clearly communicate your thought process and the steps you're taking.\n",
    "Task Outlining: If a task requires multiple steps or tools, outline your approach before beginning.\n",
    "Transparency and Accuracy\n",
    "Clarity: Always be clear about what you're doing. If you're running code, say so.\n",
    "Honesty: If you're unsure about something or if a task is beyond your capabilities, communicate this clearly.\n",
    "Real Results: Do not present hypothetical results as actual outcomes. Only report real results from your code execution.\n",
    "Interaction Style\n",
    "Concise Responses: Be concise in simple queries but provide detailed explanations for complex tasks.\n",
    "Technical Language: Use technical language appropriately, but be prepared to explain concepts in simpler terms if asked.\n",
    "Proactive Information: Proactively offer relevant information or alternative approaches that might be helpful.\n",
    "Continuous Improvement\n",
    "Clarification and Follow-Up: After completing a task, ask if the user needs any clarification or has follow-up questions.\n",
    "Feedback Receptivity: Be receptive to feedback and adjust your approach accordingly.\n",
    "Remember, your goal is to provide accurate, helpful, and insightful assistance by leveraging your unique capabilities in code execution and data analysis. Always strive to give the most practical and effective solution to the user's request.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cbcca6-28d3-4db3-a0f0-96d03e983f1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bedrock Agent Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74ed08a9-cb47-4e04-888f-67554b43fbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Creation in Process...\n",
      "Checking for agent status of 'NOT_PREPARED'...\n",
      "Agent status: CREATING\n",
      "Agent status: NOT_PREPARED\n"
     ]
    }
   ],
   "source": [
    "print(\"Agent Creation in Process...\")\n",
    "\n",
    "# Create the Bedrock Agent\n",
    "# This section initiates the creation of a new Bedrock Agent with the specified parameters:\n",
    "# - agentName: The name of the agent, appended with a random suffix to ensure uniqueness.\n",
    "# - foundationModel: The foundation model to be used by the agent (e.g., 'anthropic.claude-3-sonnet-20240229-v1:0').\n",
    "# - instruction: The detailed instructions defining the agent's personality, behavior, and capabilities.\n",
    "# - agentResourceRoleArn: The ARN of the IAM role assigned to the agent, granting necessary permissions.\n",
    "response = bedrock_agent.create_agent(\n",
    "    agentName=f\"{agentName}-{randomSuffix}\",\n",
    "    foundationModel=foundationModel,\n",
    "    instruction=instruction,\n",
    "    agentResourceRoleArn=roleArn,\n",
    ")\n",
    "\n",
    "# Extract the agentId from the response for further operations.\n",
    "agentId = response['agent']['agentId']\n",
    "\n",
    "print(\"Checking for agent status of 'NOT_PREPARED'...\")\n",
    "\n",
    "# Wait for the agent to reach the 'NOT_PREPARED' status.\n",
    "# The agent creation process involves multiple steps, and this loop ensures we proceed only when the agent reaches the 'NOT_PREPARED' status.\n",
    "# This status indicates that the agent has been created but is not yet fully prepared for use.\n",
    "agentStatus = ''\n",
    "while agentStatus != 'NOT_PREPARED':\n",
    "    # Retrieve the current status of the agent.\n",
    "    response = bedrock_agent.get_agent(\n",
    "        agentId=agentId\n",
    "    )\n",
    "    agentStatus = response['agent']['agentStatus']\n",
    "    print(f\"Agent status: {agentStatus}\")\n",
    "    time.sleep(2)  # Wait for 2 seconds before checking the status again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f41c74-98db-4786-a320-9e9213412169",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Enabling Code interpreter feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1953cd18-9fd0-4a56-aa26-aee0f42b2222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring code interpreter for the agent...\n",
      "Waiting for action group status of 'ENABLED'...\n",
      "Action Group status: ENABLED\n",
      "Preparing the agent...\n",
      "Waiting for agent status of 'PREPARED'...\n",
      "Agent status: PREPARING\n",
      "Agent status: PREPARED\n",
      "Creating an agent alias...\n",
      "Agent alias status: CREATING\n",
      "Agent alias status: CREATING\n",
      "Agent alias status: PREPARED\n",
      "Done.\n",
      "\n",
      "agentId: 1NZTBM0AAM, agentAliasId: IJA77PCKYX\n"
     ]
    }
   ],
   "source": [
    "print(\"Configuring code interpreter for the agent...\")\n",
    "\n",
    "# Create the agent action group\n",
    "# This section configures the code interpreter action group for the agent with the specified parameters:\n",
    "# - actionGroupName: The name of the action group.\n",
    "# - actionGroupState: The state of the action group, set to 'ENABLED'.\n",
    "# - agentId: The ID of the agent to which this action group belongs.\n",
    "# - agentVersion: The version of the agent, set to 'DRAFT'.\n",
    "# - parentActionGroupSignature: The predefined signature 'AMAZON.CodeInterpreter' enables the agent to generate, run, and troubleshoot code.\n",
    "#   Note: The 'description', 'apiSchema', and 'actionGroupExecutor' fields must be left blank for this action group.\n",
    "response = bedrock_agent.create_agent_action_group(\n",
    "    actionGroupName='CodeInterpreterAction',\n",
    "    actionGroupState='ENABLED',\n",
    "    agentId=agentId,\n",
    "    agentVersion='DRAFT',\n",
    "    parentActionGroupSignature='AMAZON.CodeInterpreter'\n",
    ")\n",
    "\n",
    "# Extract the actionGroupId from the response for further operations.\n",
    "actionGroupId = response['agentActionGroup']['actionGroupId']\n",
    "\n",
    "print(\"Waiting for action group status of 'ENABLED'...\")\n",
    "\n",
    "# Wait for the action group to reach the 'ENABLED' status.\n",
    "# This loop ensures that the action group is fully enabled before proceeding.\n",
    "# The 'ENABLED' status indicates that the action group is ready for use.\n",
    "actionGroupStatus = ''\n",
    "while actionGroupStatus != 'ENABLED':\n",
    "    # Retrieve the current status of the action group.\n",
    "    response = bedrock_agent.get_agent_action_group(\n",
    "        agentId=agentId,\n",
    "        actionGroupId=actionGroupId,\n",
    "        agentVersion='DRAFT'\n",
    "    )\n",
    "    actionGroupStatus = response['agentActionGroup']['actionGroupState']\n",
    "    print(f\"Action Group status: {actionGroupStatus}\")\n",
    "    time.sleep(2)  # Wait for 2 seconds before checking the status again.\n",
    "\n",
    "print(\"Preparing the agent...\")\n",
    "\n",
    "# Prepare the agent for use\n",
    "# This function call prepares the agent, making it fully ready for operation.\n",
    "response = bedrock_agent.prepare_agent(\n",
    "    agentId=agentId\n",
    ")\n",
    "\n",
    "print(\"Waiting for agent status of 'PREPARED'...\")\n",
    "\n",
    "# Wait for the agent to reach the 'PREPARED' status.\n",
    "# This loop ensures that the agent is fully prepared before proceeding.\n",
    "# The 'PREPARED' status indicates that the agent is ready for deployment.\n",
    "agentStatus = ''\n",
    "while agentStatus != 'PREPARED':\n",
    "    # Retrieve the current status of the agent.\n",
    "    response = bedrock_agent.get_agent(\n",
    "        agentId=agentId\n",
    "    )\n",
    "    agentStatus = response['agent']['agentStatus']\n",
    "    print(f\"Agent status: {agentStatus}\")\n",
    "    time.sleep(2)  # Wait for 2 seconds before checking the status again.\n",
    "\n",
    "print(\"Creating an agent alias...\")\n",
    "\n",
    "# Create an alias for the agent\n",
    "# This section creates an alias for the agent with the specified parameters:\n",
    "# - agentAliasName: The name of the alias.\n",
    "# - agentId: The ID of the agent to which this alias belongs.\n",
    "response = bedrock_agent.create_agent_alias(\n",
    "    agentAliasName='test',\n",
    "    agentId=agentId\n",
    ")\n",
    "\n",
    "# Extract the agentAliasId from the response for further operations.\n",
    "agentAliasId = response['agentAlias']['agentAliasId']\n",
    "\n",
    "# Wait for the agent alias to be prepared.\n",
    "# This loop ensures that the agent alias is fully prepared before proceeding.\n",
    "# The 'PREPARED' status indicates that the agent alias is ready for use.\n",
    "agentAliasStatus = ''\n",
    "while agentAliasStatus != 'PREPARED':\n",
    "    # Retrieve the current status of the agent alias.\n",
    "    response = bedrock_agent.get_agent_alias(\n",
    "        agentId=agentId,\n",
    "        agentAliasId=agentAliasId\n",
    "    )\n",
    "    agentAliasStatus = response['agentAlias']['agentAliasStatus']\n",
    "    print(f\"Agent alias status: {agentAliasStatus}\")\n",
    "    time.sleep(2)  # Wait for 2 seconds before checking the status again.\n",
    "\n",
    "print('Done.\\n')\n",
    "\n",
    "# Print the final agent and alias IDs.\n",
    "print(f\"agentId: {agentId}, agentAliasId: {agentAliasId}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e9ca6b-340d-4f6e-99d1-39f562e3554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining the Model_invoke funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15567ccc-906b-485e-8b7f-40f1a79d1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_agent_runtime = boto3.client(service_name = 'bedrock-agent-runtime', region_name = region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e95a42a-1e76-407c-afd6-806ed60a276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_invoke(inputText, showTrace=True, endSession=False):\n",
    "    \"\"\"\n",
    "    Invokes the Bedrock Agent with the given input text, processes the response,\n",
    "    and handles any exceptions that may occur during the process.\n",
    "\n",
    "    Parameters:\n",
    "    inputText (str): The prompt text to send to the agent.\n",
    "    showTrace (bool): Whether to enable trace to track the agent's reasoning process (default is False).\n",
    "    endSession (bool): Whether to end the session with the agent after the invocation (default is False).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Invoke the Bedrock Agent with the provided input text.\n",
    "        # This function sends a prompt to the agent and retrieves the agent's response.\n",
    "        response = bedrock_agent_runtime.invoke_agent(\n",
    "            agentAliasId=agentAliasId,   # [REQUIRED] The alias of the agent to use.\n",
    "            agentId=agentId,             # [REQUIRED] The unique identifier of the agent to use.\n",
    "            sessionId=sessionId,         # [REQUIRED] The unique identifier of the session. Use the same value across requests to continue the same conversation.\n",
    "            inputText=inputText,         # The prompt text to send to the agent.\n",
    "            endSession=endSession,       # Specifies whether to end the session with the agent or not.\n",
    "            enableTrace=showTrace,       # Specifies whether to enable trace to track the agent's reasoning process.\n",
    "        )\n",
    "\n",
    "        # The response of this operation contains an EventStream member.\n",
    "        event_stream = response[\"completion\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "         # Check if trace is enabled and process the trace information if available\n",
    "        if showTrace and \"trace\" in response:\n",
    "            trace_info = response[\"trace\"]\n",
    "            print(\"Trace information:\")\n",
    "            for trace_event in trace_info:\n",
    "                print(trace_event)\n",
    "                \n",
    "\n",
    "        # Iterate through the EventStream to process the agent's response.\n",
    "        for event in event_stream:\n",
    "            # Each event contains a chunk, which is a part of the agent's response.\n",
    "            if 'chunk' in event:\n",
    "                chunk = event['chunk']\n",
    "                if 'bytes' in chunk:\n",
    "                    # Decode the chunk bytes to UTF-8 text and print the response part.\n",
    "                    text = chunk['bytes'].decode('utf-8')\n",
    "                    print(f\"Model Response : {text}\")\n",
    "                else:\n",
    "                    # Print a message if the chunk does not contain bytes.\n",
    "                    print(\"Chunk received does not contain 'bytes' field.\")\n",
    "            else:\n",
    "                # Print a message if the event does not contain a chunk.\n",
    "                print(\"Event received does not contain 'chunk' field.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Print any exception that occurs during the agent invocation.\n",
    "        print(f\"An error occurred during agent invocation: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93000e48-b4f1-4ca8-a6be-9c62c4086a62",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model invoke with analysis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "617898c1-27e9-4bae-8de1-88a5a3e21633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event received does not contain 'chunk' field.\n",
      "Event received does not contain 'chunk' field.\n",
      "Event received does not contain 'chunk' field.\n",
      "Event received does not contain 'chunk' field.\n",
      "Event received does not contain 'chunk' field.\n",
      "Event received does not contain 'chunk' field.\n",
      "Event received does not contain 'chunk' field.\n",
      "Event received does not contain 'chunk' field.\n",
      "Event received does not contain 'chunk' field.\n",
      "Event received does not contain 'chunk' field.\n",
      "Event received does not contain 'chunk' field.\n",
      "Event received does not contain 'chunk' field.\n",
      "Event received does not contain 'chunk' field.\n",
      "Event received does not contain 'chunk' field.\n",
      "Event received does not contain 'chunk' field.\n",
      "Model Response : The fastest car in the provided data is the Tesla Model S Plaid with a 0-60 mph time of 1.99 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sessionId = str(uuid.uuid4())\n",
    "\n",
    "model_invoke(\"\"\"Using the car speed metrics, what is fastest car\n",
    "\n",
    "serial_no,car,model,0_to_60_time\n",
    "1,Ford,Mustang GT,4.3\n",
    "2,Chevrolet,Camaro SS,4.0\n",
    "3,Dodge,Challenger R/T,4.8\n",
    "4,Tesla,Model S Plaid,1.99\n",
    "5,BMW,M3,3.8\n",
    "6,Mercedes-Benz,AMG C63,3.9\n",
    "7,Audi,RS5,3.7\n",
    "8,Porsche,911 Carrera,4.2\n",
    "9,Lamborghini,Huracan Evo,2.9\n",
    "10,Ferrari,F8 Tributo,2.9\n",
    "11,McLaren,720S,2.8\n",
    "12,Aston Martin,Vantage,3.5\n",
    "13,Jaguar,F-Type R,3.5\n",
    "14,Nissan,GT-R,2.7\n",
    "15,Toyota,GR Supra,3.9\n",
    "\n",
    ".\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d0aab3-5008-40ab-902d-e432ef8ee875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
